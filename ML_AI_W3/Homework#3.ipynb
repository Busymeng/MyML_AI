{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d1d79f",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "## Problem 1 Web-scraping vs API-calling...\n",
    "\n",
    "#### <font style=\"color:rgb(180,120,10);\"><b>Problem 1a</b>:  &nbsp; add a second function</font>\n",
    "\n",
    "For this part, you will scrape the [alien-and-snack](https://www.cs.hmc.edu/%7Edodds/demo.html) page and shows how to\n",
    "extract the best snacks from it, even though they're \"wrapped\" in HTML &lt;li&gt; tags... .write a second function that removes the extra stuff - such as <font style=\"color:rgb(169,0,100);\"> &lt;li class=\"latte\"&gt;Poptarts&lt;/li &gt;</font> - from the start of a string. Then outputs the HTML \"contents\" of this list item, which - in this case - is \" Poptarts \".\n",
    "Don't worry about the details of the spaces on either side. (It's worth knowing that\n",
    "\" stuff \".strip() will return \"stuff\" .)\n",
    "\n",
    "Then, use the function in the loop above to show that it works -- and that you've scraped the best snacks!\n",
    "\n",
    "<font>The line I added to the loop  was this &nbsp;&nbsp; <tt style=\"color:rgb(169,0,100);\">substring = remove_li(substring)</tt>  &nbsp;&nbsp; Vary as you see fit...</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292798a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your function here\n",
    "# then, use it in the in-class note to show that we have only the pure snacks we sought... !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d571ed2",
   "metadata": {},
   "source": [
    "#### <font style=\"color:rgb(180,120,10);\"><b>Problem 1b</b>:  &nbsp; Scrape another page!</font>\n",
    "\n",
    "This part invites you to do a little bit of \"real\" web scraping -- that is, grabbing the HTML source of a page and then extracting one or more intentional, interesting pieces of information from it. (You get to define interesting... .)\n",
    "\n",
    "For this part, find another page - as large and complicated as you'd like - and scrape one or more pieces of information from it...\n",
    "  + Be sure that your information-extraction involves some use of the function <tt>find</tt>  and/or regular expression\n",
    "  + the details... are up to you!\n",
    "  \n",
    "**Past ideas:**\n",
    "- Any page will work -- perhaps the TSL, and see which college is mentioned the most...\n",
    "- Perhaps a Wikipedia page or a landing page for an organization...\n",
    "- as a second example, there is a not-very-earnest _Superbowl-predictor_ at the very end of the in-class notebook.\n",
    "  - It creates a \"two-hop\" chain of web-scraping reasoning: first, grabbing important team stats\n",
    "  - ... then uses those stats to compute a predicted score (and a predicted winner)... We'll see! ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd2c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your work here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4ba79",
   "metadata": {},
   "source": [
    "## Problem 2: Writing your own markdown-to-markup web engine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbbaf00",
   "metadata": {},
   "source": [
    "Most often, HTML is not written by hand: instead, other computational processes output it.\n",
    "\n",
    "This problem will use Python to create a web-templating engine that converts markdown, an\n",
    "easy-to-read language for annotating content, into HTML. \n",
    "\n",
    "There are excellent markdowneditors,\n",
    "Jupyter notebooks, browsers, or stand-alone examples such as [Dillinger](https://dillinger.io/). \n",
    "\n",
    "This problem asks you to get the feel of what it would be like to <u><i>implement</i></u> such an editor. It's unlikely any of them\n",
    "directly renders markdown into visual form -- instead, they convert markdown into the\n",
    "ubiquitous markup of HTML and the web, and then use existing renderers to display the results.\n",
    "\n",
    "In addition, you'll have a chance to explore CSS and HTML via the page your web-engine\n",
    "generates!\n",
    "\n",
    "That is, _writing your own web engine_ !  A **web engine** is an informal term for software that makes content visible in a browser. For example,\n",
    "+ we've been writing _markdown_ and then asking VSCode (or a browser) to render it as _markup_ \n",
    "  + to do this, the syntax <tt>_italic_</tt> gets transformed into <tt><i>italic</i></tt> by a \"markdown-to-markup\" web engine\n",
    "  + from there, the browser can render the latter using its markup: &nbsp; <i>italic</i>\n",
    "  + (in fact, it uses another web engine to go from markup to visible content)  \n",
    "  \n",
    "+ We will focus on implementing the **markdown-to-markup** step - and extending it, by adding a few features of your own design "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c8846",
   "metadata": {},
   "source": [
    "Check out the starting point for problem 2, you will find that it\n",
    "- Defines a large, multi-line string of markdown with information on the 5Cs...\n",
    "- Defines three conversion functions, each of which uses a regular expression to replace (substitute) markdown syntax with markup syntax\n",
    "- And has a cell that runs the entire workflow:\n",
    "    - it starts with the markdown in the string original_markdown\n",
    "    - it transforms the lines in that string via three functions:\n",
    "        - handle_newlines\n",
    "        - handle_headers\n",
    "        - handle_code\n",
    "    - and then writes out the results to the file output.html\n",
    "    - which you will be able to open - or reload - in a browserâ€¦\n",
    "- It's worth looking over those transformations:\n",
    "    - They iterate, line-by-line, over the markdown lines\n",
    "    - Extra newlines become <br> (HTML newlines)\n",
    "- actual newlines have little-to-no impact on what HTML looks like\n",
    "    - Lines starting with # become first-level headers &lt;h1&gt; &lt;/h1&gt;\n",
    "        - You need to update it for h1 through h6!\n",
    "    - Text surrounded by the backtick character `code` becomes <tt>code</tt>\n",
    "        - Right now, it's a greedy match: all the text possible!\n",
    "        - You should fix this, changing the capture group (.*?) or ([^`]*)\n",
    "        - For examples like this, regular expressions are helpful and powerful..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68364e99",
   "metadata": {},
   "source": [
    "**Your task** is to understand the current code -- and then improve its web-engine abilities.\n",
    "\n",
    "As you've come to expect, this is too open-ended. In the limit, it could lead to a full web-content\n",
    "rendering engineâ€¦ Our goal is not to go that far, but to get the feel for it:\n",
    "\n",
    "Ideally, your final result should\n",
    "1. Handle all six levels of headers &lt;h1&gt; through &lt;h6&gt; by translating lines that start with that number of hashtags, e.g., ## becomes an &lt;h2&gt; &lt;/h2&gt; line, etc.\n",
    "1. Handle at least these five word-stylings:\n",
    "    - Implement *Italic* &lt;i&gt;&lt;/i&gt; with asterisks \\*italic\\* and underscores \\_italic\\_\n",
    "    - Implement **Bold** &lt;b&gt;&lt;/b&gt; with asterisks \\*\\*bold\\*\\* and underscores \\_\\_bold\\_\\_\n",
    "    - Implement ~~Strikethrough~~ &lt;s&gt;&lt;/s&gt; with tildes \\~\\~strikethrough\\~\\~\n",
    "    - Handle unordered lists code\n",
    "        - which makes lists from elements, where \"+\" is the initial characterâ€¦\n",
    "        - No need to do more than this for the list-handlingâ€¦\n",
    "        - Totally ok to make a list for each element! (Trickier + extra: how to make a single list across all elements?)\n",
    "    - Implement URL names and links as \\[urlname\\]\\(urllink\\)\n",
    "        - for example, \\[Google\\]\\(https://www.google.com \\)\n",
    "        - becomes <a href=\"https://www.google.com\">Google</a>\n",
    "        - You'll have to use TWO capture groups (.*?) which become \\1 and \\2\n",
    "1. And at least three more features/stylings of your own design. For ideas:\n",
    "    - Create regular asterisks/underscores if they're preceded by a backslash:\n",
    "        - thus, \\\\\\*Wow\\\\\\* would yield \\*Wow\\* instead of *Wow* (Wow!)\n",
    "        - similarly, \\\\\\_\\\\\\_Yikes\\\\\\_\\\\\\_ would yield \\_\\_ Yikes\\_\\_ instead of __Yikes__ (Yikes!)\n",
    "    - <ins>Underscore</ins>? Super<sup>script</sup> Sub<sub>script</sub>\n",
    "    - In-line styling (color, font, etc.) - this will overlap with CSS\n",
    "        - For example, color <font style=\"color:#520099;\">CMC</font> with its school colors of <span style=\"background-color: #FFFF00\">background</span>\n",
    "        - Make rival school-names invisible, e.g., ```POM``` etc. ...\n",
    "    - Tool-tips (this is tricky! [CSS tooltips reference](https://www.w3schools.com/css/css_tooltip.asp))\n",
    "    - Tables (this is also tricky! [CSS tables reference](https://www.w3schools.com/css/css_table.asp))\n",
    "    - Blinking text via [CSS](https://www.w3schools.com/css/css3_animations.asp) (Annoying! and very tricky. \\<blink\\> is decommissioned!)\n",
    "    - Python evaluation of code!?! (cool and dangerous - use Python's eval)\n",
    "    - Other human languages? (I'm not sure what this would mean, to be honest, but it's a thought!)\n",
    "        - Be sure to explain in your cells what you implemented!\n",
    "- As you go, try out each transformation in the same way...\n",
    "    - keep adding more transformation functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9553e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Put your work here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365d93a",
   "metadata": {},
   "source": [
    "## Problem 3: Open-ended exploration with files, web or csv...\n",
    "\n",
    "The hw3pr3 problem caps the work of this whole four-week module, which has been\n",
    "considering all the worlds files part of what you're able to script -- and to practice doing just\n",
    "that!\n",
    "Here, your task is to find another file -- either a csv (a comma-separated-value file, think of it\n",
    "as \"a spreadsheet\") or another web-scraped JSON/HTML/something else file...\n",
    "... and connect two hops of information gathering! The goal is to grab information from the\n",
    "first \"hop\" and then leverage that information to specialize the second \"hop.\" Here are a\n",
    "couple of examples:\n",
    "1. The \"Superbowl predictor\" example first grabs the team colors from a team's wikipedia page. (It also works for colleges/schools). Then, it uses a \"color-popularity page\" (from a site called the \"Top Tens\") in order to map each color to a score.\n",
    "\n",
    "    Admittedly, this score is unlikely to be related to the outcome of a game, much less the superbowl, but nonsensical leaps are 100% ok! It then adds the scores to make a game-prediction and prints the output.\n",
    "1.  The \"ISSpy the ISS\" option would be to use last week's ISS-location calls to find where the ISS is currently (in lat/long). Then, use the cities.csv file (in this week's google drive) to find the closest city to the ISS, and print that out.\n",
    "\n",
    "If you take this kind of route, please do be careful not to call the ISS API (or any API) for each\n",
    "iteration of the loop over your file! This will result in your machine being banned from making\n",
    "future API calls, at least for a while (note: we have first-hand experience with thisðŸ™‚)\n",
    "\n",
    "Instead, call the API once, extract its data, and then loop using that extracted data as many\n",
    "times as you'd like. It's much faster for your code (no API-call overhead) and much happier for\n",
    "your network and the API's server.\n",
    "\n",
    "The world's files are now yours!\n",
    "\n",
    "The next module practices methods for model-building with - some of - those files, more often\n",
    "the csv-type (they're more modelable) than the HTML-type (which are messier...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517dbf00",
   "metadata": {},
   "source": [
    "#### <font style=\"color:rgb(180,120,10);\"><b>Problem 3</b> &nbsp;&nbsp; _Option #1_ &nbsp;&nbsp; What city can see the ISS right now? </font>\n",
    "\n",
    "As [this article](https://www.space.com/how-to-track-the-international-space-station) notes, it's possible to see the ISS at dawn or dusk without a telescope (if conditions are right...)\n",
    "\n",
    "But, _where_ are conditions most right at a particular time?!\n",
    "\n",
    "This question expands the capability of last week's ISS-tracking functions:\n",
    "+ Here, you'll use the ``haversine`` Python function (not the web API call), and\n",
    "+ Write a new function that\n",
    "  + Finds the current distance of the ISS, then\n",
    "  + Uses the csv file **cities.csv**, which has all of the cities in the world with over 50,000 residents (as of 2023, acc. to [this reference](https://gist.github.com/willy-wagtail/8e035ecce41d12c98dbbdb33e42e89f4#file-world_cities-csv))\n",
    "  + Loops over the whole list of cities, checking the distance to each, and\n",
    "+ Returns the city that is **currently closest** to the ISS, as well as its computed distance to the ISS\n",
    "\n",
    "Even in keeping with the ISS's recommendation not to make a request more than every 5 seconds, you will find that you often get a new city!\n",
    "+ Wave as it goes by!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e005f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# IF you take Option #1, feel free to copy your ISS functions from week 2 into these cells \n",
    "# and continue developing from there...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Put your work here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2cff11",
   "metadata": {},
   "source": [
    "#### <font style=\"color:rgb(180,120,10);\"><b>Problem 3</b> &nbsp;&nbsp; _Option #2_ &nbsp;&nbsp; Scraping the Web's Wisdom?! </font>\n",
    "\n",
    "Alternatively, as a final problem, build a two-step web-scraping workflow that\n",
    "+ finds some piece of information from one site you choose\n",
    "  + for example, the superbowl-predictor, below, goes to the wikipedia page to get a team's colors...\n",
    "+ then, makes a _second_ web-scrape or web-search that **uses** that information...\n",
    "  + below, it uses a \"top ten colors\" website to look up \"scores\" for each color\n",
    "  + it then sums the scores to get a predicted superbowl game-score...  and thus, a predicted winner!\n",
    "\n",
    "Admittedly, this is a silly example -- yours can be, as well -- or something more purposeful. <font size=\"-2\">though we'll see on Sunday how close this is...</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Put your work here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116e086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
